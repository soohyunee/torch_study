{"cells":[{"metadata":{},"cell_type":"markdown","source":"### TPU 사용하는 법\n1) https://pytorch.org/xla/release/1.7/index.html<br>\n2) https://pytorch.org/xla/release/1.7/index.html#xla-tensor-deep-dive<br><br><br>\n### torchtext 사용하는 법\n1) https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/A%20-%20Using%20TorchText%20with%20Your%20Own%20Datasets.ipynb<br><br>\n#### 1) 이 코드를 전부 돌려보고 정상적으로 돌아가는지 확인한다 (stopwords 처리 안함)<br>\n#### 2) stopwords를 삭제하고 나서, 1)번과 성능 차이를 본다<br>\n#### 3) torchtext 버전으로 코드를 수정해보고, 또 stopwords 삭제도 해보면서 성능 차이를 확인한다.<br><br><br>\n### References<br>\n1) https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb"},{"metadata":{"trusted":true},"cell_type":"code","source":"# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n# !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch_xla\n# import torch_xla.core.xla_model as xm\n\n# # https://www.kaggle.com/tanlikesmath/the-ultimate-pytorch-tpu-tutorial-jigsaw-xlm-r","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport pickle\nimport os, re, gensim\nos.environ['XLA_USE_BF16'] = '1'\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\nfrom nltk.corpus import stopwords\nfrom collections import defaultdict\nstop = stopwords.words('english')\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# device = xm.xla_device()\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":39,"outputs":[{"output_type":"stream","text":"/kaggle/input/posneg-for-cnn4sc/rt-polarity.pos\n/kaggle/input/posneg-for-cnn4sc/rt-polarity.neg\n/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\n/kaggle/input/cnn-word-vector-json/data.json\n/kaggle/input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### word_vecs 만들어주기\n## dict 자료형에, word와 wordvector가 함께 있어야 함, 코드 에러가 안나면 limit=500000으로 변경하기 \nword_vecs = gensim.models.KeyedVectors.load_word2vec_format(\"/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\", binary=True, limit=700000)","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## modified codes in https://github.com/yoonkim/CNN_sentence \nclass preprocess:\n    def __init__(self, word_vecs, save=False):\n        self.k = 300     # the embedding dimension of pretrained vector noted at the paper\n        self.revs = []\n        self.vocab_size = 0\n        self.max_len = 56 # the value what yoon used at his codes\n        self.word_idx_map = dict()\n        self.word_vecs = word_vecs\n        self.stop = set(stopwords.words('english'))\n        self.save = save\n\n        \n    def clean_str(self, string):\n        ## string이 sentence로 들어와서, self.stop으로 못 거름...=_=;\n        ## 우선 stopwords 안 거르는걸로 해서 함 돌려보자.\n        string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)     \n        string = re.sub(r\"\\'s\", \" \\'s\", string) \n        string = re.sub(r\"\\'ve\", \" \\'ve\", string) \n        string = re.sub(r\"n\\'t\", \" n\\'t\", string) \n        string = re.sub(r\"\\'re\", \" \\'re\", string) \n        string = re.sub(r\"\\'d\", \" \\'d\", string) \n        string = re.sub(r\"\\'ll\", \" \\'ll\", string) \n        string = re.sub(r\",\", \" , \", string) \n        string = re.sub(r\"!\", \" ! \", string) \n        string = re.sub(r\"\\(\", \" \\( \", string) \n        string = re.sub(r\"\\)\", \" \\) \", string) \n        string = re.sub(r\"\\?\", \" \\? \", string) \n        string = re.sub(r\"\\s{2,}\", \" \", string)\n        return string.strip().lower()\n    \n    \n    def build_data_cv(self, cv=10):\n        pos_file = \"/kaggle/input/posneg-for-cnn4sc/rt-polarity.pos\"\n        neg_file = \"/kaggle/input/posneg-for-cnn4sc/rt-polarity.neg\"\n\n        file_list = [pos_file, neg_file]    \n        self.vocab = defaultdict(float)\n\n        for file in file_list:\n            with open(file, \"rb\") as f:\n                for line in f: \n                    try:\n                        line = line.decode(\"utf-8\")\n                    except UnicodeDecodeError:\n                        line = line.decode('latin-1')\n\n                    rev = []\n                    rev.append(line.strip())\n                    orig_rev = self.clean_str(\" \".join(rev))\n        \n                    words = set(orig_rev.split())\n                    \n                    if len(words) > self.max_len:\n                        self.max_len = len(words)\n                    \n                    for word in words:\n                        try:\n                            self.vocab[word] += 1\n                            self.vocab_size += 1\n                        except:\n                            self.vocab[word] = 1\n                            self.vocab_size += 1\n                            \n                    if file[-3:] == \"pos\":        \n                        datum = {\"y\": 1,\n                                \"text\": orig_rev,\n                                \"split\": np.random.randint(0,cv)}\n                        ## np.random.randint는 discrete uniform distribution\n                        \n                    elif file[-3:] == \"neg\":\n                        datum = {\"y\": 0,\n                                \"text\": orig_rev,\n                                \"split\": np.random.randint(0,cv)}\n                    self.revs.append(datum)\n        \n        return self.revs, self.vocab, self.max_len\n    \n    \n    def add_unknown_words(self, min_df=1):\n        cnt = 0\n        for word in self.vocab:\n            if word not in self.word_vecs and self.vocab[word] >= min_df:\n                self.word_vecs[word] = np.random.uniform(-0.25,0.25,self.k)  \n                self.vocab_size += 1\n                cnt += 1\n        print(cnt, ' of unknown words were here')          \n\n    def get_W(self):\n        self.revs, self.vocab, self.max_len = self.build_data_cv()\n        self.add_unknown_words()\n        self.W = np.zeros(shape=(self.vocab_size+1, self.k), dtype='float32')            \n        self.W[0] = np.zeros(self.k, dtype='float32')\n        i = 1\n        for word in self.vocab:\n            self.W[i] = self.word_vecs[word]\n            self.word_idx_map[word] = i\n            i += 1\n            \n        if self.save:\n            self.save_file()\n#         print('W shape:', self.W.shape)\n        # word_idx_map은 dictionary 타입이다.\n        return self.W, self.word_idx_map, self.revs, self.max_len\n    \n    def save_file(self):\n        data = {'revs':self.revs,\n               'w':self.W,\n               'word_idx_map':self.word_idx_map,\n               'vocab':self.vocab}\n        \n        pd.Series(data).to_json('data.json')\n        print('making a json file completed!')","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## when data.json doesn't exist \n# pre = preprocess(word_vecs, save=True)\n# w, word_idx_map, revs, max_len = pre.get_W()\n\n## if data.json exist\nwith open(\"/kaggle/input/cnn-word-vector-json/data.json\") as json_file:\n    files = json.load(json_file)\n    \nrevs, w, word_idx_map, vocab = files['revs'], files['w'], files['word_idx_map'], files['vocab']","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('w type:',type(w))\nprint('revs type:',type(revs))\nprint('revs shape:',len(revs))\n\n## word_vecs : dictionary형, 벡터를 보고프면 word_vecs['word']","execution_count":43,"outputs":[{"output_type":"stream","text":"w type: <class 'list'>\nrevs type: <class 'list'>\nrevs shape: 10662\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Build each Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Make_Dataset(TensorDataset):\n    def __init__(self, word_idx_map, xy):\n        '''\n        self.xy : a sentence, string type\n        '''\n        super().__init__()\n        self.xy = xy\n        self.max_len = 56\n        self.word_idx_map = word_idx_map\n        \n    def __len__(self):\n        return len(self.xy)\n        \n    def __getitem__(self, idx):\n        splitted_sentence = self.xy[idx]['text'].split()\n        tmp = []\n        for word in splitted_sentence:\n            tmp.append(self.word_idx_map[word])\n            \n        if len(tmp) < self.max_len:\n            for _ in range(len(tmp), self.max_len):\n                tmp.append(0)\n                \n        if self.xy[idx]['y'] in [0,1]: \n            return {'input_ids':torch.LongTensor(tmp).flatten(),\n                    'target':torch.tensor(self.xy[idx]['y'])}\n    \n        else:                                               # mr-dataset에서는 여기에 걸리는 케이스가 없음. 전부 label이 존재함.. \n#             print('wwhhhhhhhhhhaaaaaaaaaattt:',self.xy[idx]['y'])\n            return {'input_ids':torch.LongTensor(tmp).flatten()}","execution_count":44,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### build a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Kfold_Split(revs, word_idx_map, test_fold_id):\n    train = []\n    test = []\n    for datum in revs:\n        if datum['split'] == test_fold_id:\n            test.append(datum)\n        else:\n            train.append(datum)   \n\n    train_dataset = Make_Dataset(word_idx_map=word_idx_map, xy=train)\n    test_dataset = Make_Dataset(word_idx_map=word_idx_map, xy=test)\n    \n    print('train length:', len(train_dataset))\n    print('test length:', len(test_dataset))\n## 우선 코드 전체적으로 쭈욱 한 번 돌리고 나서, 여길 수정하자.\n#     proper_batch_size = int(len(vocab)/10)\n#     print('proper:',proper_batch_size)\n\n    train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True, drop_last=True)\n    test_loader = DataLoader(test_dataset, batch_size=50, shuffle=True, drop_last=True)\n    return train_loader, test_loader","execution_count":45,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### pre-trained vectors를 google negative300.bin으로 넣어주는 방법\n1) https://discuss.pytorch.org/t/expected-input-to-torch-embedding-layer-with-pre-trained-vectors-from-gensim/37029<br>\n2) static과 non-static의 구분을 nn.Embedding.from_pretrained(freeze=True/False)로 해줌 : https://github.com/aisolab/nlp_classification/blob/master/Convolutional_Neural_Networks_for_Sentence_Classification/model/ops.py"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Cnn_Model(nn.Module):\n    def __init__(self, W, word_vecs):\n        super(Cnn_Model, self).__init__()\n        self.n_filters = 100\n        self.input_dim = 1   # 그냥 text니깐 1임. vision일 경우 3 \n        self.word_vecs = torch.FloatTensor(word_vecs.vectors)\n        \n        self.W = torch.tensor(W)\n        ## nn.embedding은 2-dim float tensor로 만들어지고,\n        ## from_pretrained에서의 freeze는 기본적으로 True이다.\n        self.embedding = nn.Embedding.from_pretrained(self.word_vecs, freeze=False)\n        self.conv3_layer = nn.Conv2d(self.input_dim, self.n_filters, kernel_size=(3,300))\n        self.conv4_layer = nn.Conv2d(self.input_dim, self.n_filters, kernel_size=(4,300))\n        self.conv5_layer = nn.Conv2d(self.input_dim, self.n_filters, kernel_size=(5,300))\n        \n        ## 우선 filter_size를 3으로 줬을 때\n        self.fc = nn.Linear(3*self.n_filters, 1) \n        self.dropout = nn.Dropout()\n        \n    def forward(self, x):\n#         print('first x:', x.size())                  # 50, 56                \n        x = self.embedding(self.W)                       # 50, 56, 300    \n#         print('second x:', x.size())        \n        x = x.unsqueeze(1)                          # 50, 1, 56,, 300                   \n#         print('third x:', x.size())\n        ## make a feature map for each filter\n        f3 = F.relu(self.conv3_layer(x).squeeze(3))  # 50, 10, 54\n        f4 = F.relu(self.conv4_layer(x).squeeze(3))  # 50, 10, 53\n        f5 = F.relu(self.conv5_layer(x).squeeze(3))  # 50, 10, 52\n#         print('fourth f3:', f3.size())\n#         print('fourth f4:', f4.size())\n#         print('fourth f5:', f5.size())\n\n        x3 = F.max_pool1d(f3, f3.shape[2]).squeeze(2)  # 50, 10\n        x4 = F.max_pool1d(f4, f4.shape[2]).squeeze(2)  # 50, 10\n        x5 = F.max_pool1d(f5, f5.shape[2]).squeeze(2)  # 50, 10\n#         print('fifth x3:', x3.size())\n#         print('fifth x4:', x4.size())\n#         print('fifth x5:', x5.size())\n        \n        ### a penultimate layer\n        x = self.dropout(torch.cat((x3,x4,x5), dim=1))  # 50, 30\n#         print('sixth x:', x.size())\n#         x.size()  batch_size, n_filters*len(filter_sizes)\n\n        output = self.fc(x)                          # 50, 30\n#         print('seventh x:', x.size())   \n        \n        return output.squeeze()","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb\nepochs = 25  # the value exists in original code\nNON_STATIC = True\nmodel = Cnn_Model(W=w, word_vecs=word_vecs)\nmodel.to(device)","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"Cnn_Model(\n  (embedding): Embedding(700000, 300)\n  (conv3_layer): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n  (conv4_layer): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n  (conv5_layer): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n  (fc): Linear(in_features=300, out_features=1, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def binary_accuracy(preds, y):\n    rounded_preds = torch.round(torch.sigmoid(preds))\n    correct = (rounded_preds == y).float()\n    acc = correct.sum() / len(correct)\n    return acc","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# criterion = nn.BCELoss().to(device) \n# criterion = nn.NLLLoss().to(device) # NLL 썼음.. \ncriterion = nn.BCEWithLogitsLoss().to(device) \noptimizer = optim.Adadelta(model.parameters(), rho=0.95, eps=1e-6, weight_decay=0.95)\n# optimizer = optim.Adam(model.parameters())\n\nfor i in range(0,10):\n    note = {}\n    print('iiiiiiii:', i)\n    train_loader, test_loader = Kfold_Split(revs, word_idx_map, test_fold_id=i)\n      \n    ## Training\n    for epoch in range(epochs):\n        check_loss = 0\n        \n        model.train()\n\n        for idx, data in enumerate(train_loader):\n            optimizer.zero_grad()\n\n            outputs = model(data['input_ids'].to(device))\n            loss = criterion(outputs, data['target'].type_as(outputs))\n            \n            acc = binary_accuracy(outputs, data['target'].type_as(outputs))\n            \n            loss.backward()   # 이걸로 W가 업뎃되나? 안될거 같은데. static/non-static설정 어케하나..\n            optimizer.step()\n#             xm.optimizer_step(self.optim)\n#             check_loss += loss.item()\n            if idx % 50 == 0:\n                print('epoch:', epoch,' current acc:', acc)\n#                 check_loss = 0\n\n#         note['loss'] = check_loss\n        print('training is done!')\n\n\n    ## test \n    total = 1\n    correct = 0\n    model.eval()\n\n    with torch.no_grad():\n        for data in test_loader:\n#             print('THIS IS THE DATA!:', data.size())\n#             print()\n            datas = data['input_ids'].to(device)\n            print('datas size:', datas.size())  # 50.56\n            outputs = model(datas)\n            print('outputs size:', outputs.size()) # the value should be [50,]\n            print('outputs unsq size:', outputs.unsqueeze(1))\n            \n            _, predicted = torch.max(outputs.data, \n                                     0)\n            labels = data['target'].to(device)\n            total += labels.size(0)\n            print('label size0:', labels.size(0))\n            correct += (predicted == labels).sum().item()\n\n    note['accuray'] = 100 * (correct/total)\n    print('test accuracy:', note['accuray'])\n\n    ### 이렇게 구찮은거 말고, stratifiedKFold 써서\n    ### 글구 필터도 한 방에 해서 갈 수 있는거 알아보자..\n    # https://github.com/aisolab/nlp_classification/blob/master/Convolutional_Neural_Networks_for_Sentence_Classification/model/ops.py'\n    \n    \n    ## w는 coefficient다","execution_count":49,"outputs":[{"output_type":"stream","text":"iiiiiiii: 0\ntrain length: 9576\ntest length: 1086\n","name":"stdout"},{"output_type":"error","ename":"TypeError","evalue":"embedding(): argument 'indices' (position 2) must be Tensor, not list","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-2df2d0bf596c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-cb667e6e89e7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         print('first x:', x.size())                  # 50, 56\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# 50, 56, 300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#         print('second x:', x.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                          \u001b[0;31m# 50, 1, 56,, 300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}